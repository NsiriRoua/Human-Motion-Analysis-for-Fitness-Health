{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copie de Pose classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NsiriRoua/Human-Motion-Analysis-for-Fitness-Health/blob/main/Copie_de_Pose_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vL2VrLjtHZCs"
      },
      "source": [
        "# Overview\n",
        "\n",
        "This Colab helps to create and validate a training set for the k-NN classifier described in the MediaPipe [Pose Classification](https://google.github.io/mediapipe/solutions/pose_classification.html) soultion, test it on an arbitrary video, export to a CSV and then use it in the [ML Kit sample app](https://developers.google.com/ml-kit/vision/pose-detection/classifying-poses#4_integrate_with_the_ml_kit_quickstart_app)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8OxqytxxV-e"
      },
      "source": [
        "# Step 0: Start Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGJFajURxZii"
      },
      "source": [
        "Connect the Colab to hosted Python3 runtime (check top-right corner) and then install required dependencies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsA8WJi60PaX",
        "outputId": "100dcd75-fd56-4892-f805-f9fe8ffff584",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 776
        }
      },
      "source": [
        "!pip install pillow==8.1.0\n",
        "!pip install matplotlib==3.3.4\n",
        "!pip install numpy==1.19.3\n",
        "!pip install opencv-python==4.5.1.48\n",
        "!pip install tqdm==4.56.0\n",
        "!pip install requests==2.25.1\n",
        "\n",
        "!pip install mediapipe==0.8.3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pillow==8.1.0\n",
            "  Downloading Pillow-8.1.0-cp37-cp37m-manylinux1_x86_64.whl (2.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2 MB 4.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: pillow\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed pillow-8.1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting matplotlib==3.3.4\n",
            "  Downloading matplotlib-3.3.4-cp37-cp37m-manylinux1_x86_64.whl (11.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.5 MB 4.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.4) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.4) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.4) (1.3.2)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.4) (1.19.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.4) (8.1.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.4) (3.0.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib==3.3.4) (1.15.0)\n",
            "Installing collected packages: matplotlib\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed matplotlib-3.3.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.19.3\n",
            "  Downloading numpy-1.19.3-cp37-cp37m-manylinux2010_x86_64.whl (14.9 MB)\n",
            "\u001b[?25l\r\u001b[K     |                                | 10 kB 26.3 MB/s eta 0:00:01\r\u001b[K     |                                | 20 kB 10.9 MB/s eta 0:00:02\r\u001b[K     |                                | 30 kB 7.0 MB/s eta 0:00:03\r\u001b[K     |                                | 40 kB 3.6 MB/s eta 0:00:05\r\u001b[K     |                                | 51 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |▏                               | 61 kB 4.4 MB/s eta 0:00:04\r\u001b[K     |▏                               | 71 kB 4.4 MB/s eta 0:00:04\r\u001b[K     |▏                               | 81 kB 5.0 MB/s eta 0:00:03\r\u001b[K     |▏                               | 92 kB 5.0 MB/s eta 0:00:03\r\u001b[K     |▏                               | 102 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |▎                               | 112 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |▎                               | 122 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |▎                               | 133 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |▎                               | 143 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |▎                               | 153 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |▍                               | 163 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |▍                               | 174 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |▍                               | 184 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |▍                               | 194 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |▍                               | 204 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |▌                               | 215 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |▌                               | 225 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |▌                               | 235 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |▌                               | 245 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |▌                               | 256 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |▋                               | 266 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |▋                               | 276 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |▋                               | 286 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |▋                               | 296 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |▋                               | 307 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |▊                               | 317 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |▊                               | 327 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |▊                               | 337 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |▊                               | 348 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |▊                               | 358 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |▉                               | 368 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |▉                               | 378 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |▉                               | 389 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |▉                               | 399 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |▉                               | 409 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |█                               | 419 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |█                               | 430 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |█                               | 440 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |█                               | 450 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |█                               | 460 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |█                               | 471 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |█                               | 481 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |█                               | 491 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |█                               | 501 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |█                               | 512 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |█▏                              | 522 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |█▏                              | 532 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |█▏                              | 542 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |█▏                              | 552 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |█▏                              | 563 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |█▎                              | 573 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |█▎                              | 583 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |█▎                              | 593 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |█▎                              | 604 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |█▎                              | 614 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |█▍                              | 624 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |█▍                              | 634 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |█▍                              | 645 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |█▍                              | 655 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |█▍                              | 665 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |█▌                              | 675 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |█▌                              | 686 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |█▌                              | 696 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |█▌                              | 706 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |█▌                              | 716 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |█▋                              | 727 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |█▋                              | 737 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |█▋                              | 747 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |█▋                              | 757 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |█▋                              | 768 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |█▊                              | 778 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |█▊                              | 788 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |█▊                              | 798 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |█▊                              | 808 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |█▊                              | 819 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |█▉                              | 829 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |█▉                              | 839 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |█▉                              | 849 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |█▉                              | 860 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |█▉                              | 870 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |██                              | 880 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |██                              | 890 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |██                              | 901 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |██                              | 911 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |██                              | 921 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |██                              | 931 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |██                              | 942 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |██                              | 952 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |██                              | 962 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |██                              | 972 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |██▏                             | 983 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |██▏                             | 993 kB 4.2 MB/s eta 0:00:04\r\u001b[K     |██▏                             | 1.0 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |██▏                             | 1.0 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |██▏                             | 1.0 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |██▎                             | 1.0 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |██▎                             | 1.0 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |██▎                             | 1.1 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |██▎                             | 1.1 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |██▎                             | 1.1 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |██▍                             | 1.1 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |██▍                             | 1.1 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |██▍                             | 1.1 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |██▍                             | 1.1 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |██▍                             | 1.1 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |██▌                             | 1.1 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |██▌                             | 1.1 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |██▌                             | 1.2 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |██▌                             | 1.2 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |██▌                             | 1.2 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |██▋                             | 1.2 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |██▋                             | 1.2 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |██▋                             | 1.2 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |██▋                             | 1.2 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |██▋                             | 1.2 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |██▊                             | 1.2 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |██▊                             | 1.2 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |██▊                             | 1.3 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |██▊                             | 1.3 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |██▊                             | 1.3 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |██▉                             | 1.3 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |██▉                             | 1.3 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |██▉                             | 1.3 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |██▉                             | 1.3 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |██▉                             | 1.3 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |███                             | 1.3 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |███                             | 1.4 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |███                             | 1.4 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |███                             | 1.4 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |███                             | 1.4 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |███                             | 1.4 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |███                             | 1.4 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |███                             | 1.4 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |███                             | 1.4 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |███                             | 1.4 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |███                             | 1.4 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |███▏                            | 1.5 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |███▏                            | 1.5 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |███▏                            | 1.5 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |███▏                            | 1.5 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |███▏                            | 1.5 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |███▎                            | 1.5 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |███▎                            | 1.5 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |███▎                            | 1.5 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |███▎                            | 1.5 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |███▎                            | 1.5 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |███▍                            | 1.6 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |███▍                            | 1.6 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |███▍                            | 1.6 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |███▍                            | 1.6 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |███▍                            | 1.6 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |███▌                            | 1.6 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |███▌                            | 1.6 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |███▌                            | 1.6 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |███▌                            | 1.6 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |███▌                            | 1.6 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |███▋                            | 1.7 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |███▋                            | 1.7 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |███▋                            | 1.7 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |███▋                            | 1.7 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |███▋                            | 1.7 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |███▊                            | 1.7 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |███▊                            | 1.7 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |███▊                            | 1.7 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |███▊                            | 1.7 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |███▊                            | 1.8 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |███▉                            | 1.8 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |███▉                            | 1.8 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |███▉                            | 1.8 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |███▉                            | 1.8 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |███▉                            | 1.8 MB 4.2 MB/s eta 0:00:04\r\u001b[K     |████                            | 1.8 MB 4.2 MB/s eta 0:00:04"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "q7Cn7hUg1As9",
        "outputId": "dd8de9cf-aa85-4b58-8138-3547bce6e812",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7S1Dl8Dhfa2"
      },
      "source": [
        "# Codebase"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5Ay8WCLqosN"
      },
      "source": [
        "## Commons"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swiAP0RYqqVM"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "def show_image(img, figsize=(10, 10)):\n",
        "  \"\"\"Shows output PIL image.\"\"\"\n",
        "  plt.figure(figsize=figsize)\n",
        "  plt.imshow(img)\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0L6HLFd9AXmh"
      },
      "source": [
        "## Pose embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBrKOeP30RAx"
      },
      "source": [
        "class FullBodyPoseEmbedder(object):\n",
        "  \"\"\"Converts 3D pose landmarks into 3D embedding.\"\"\"\n",
        "\n",
        "  def __init__(self, torso_size_multiplier=2.5):\n",
        "    # Multiplier to apply to the torso to get minimal body size.\n",
        "    self._torso_size_multiplier = torso_size_multiplier\n",
        "\n",
        "    # Names of the landmarks as they appear in the prediction.\n",
        "    self._landmark_names = [\n",
        "        'nose',\n",
        "        'left_eye_inner', 'left_eye', 'left_eye_outer',\n",
        "        'right_eye_inner', 'right_eye', 'right_eye_outer',\n",
        "        'left_ear', 'right_ear',\n",
        "        'mouth_left', 'mouth_right',\n",
        "        'left_shoulder', 'right_shoulder',\n",
        "        'left_elbow', 'right_elbow',\n",
        "        'left_wrist', 'right_wrist',\n",
        "        'left_pinky_1', 'right_pinky_1',\n",
        "        'left_index_1', 'right_index_1',\n",
        "        'left_thumb_2', 'right_thumb_2',\n",
        "        'left_hip', 'right_hip',\n",
        "        'left_knee', 'right_knee',\n",
        "        'left_ankle', 'right_ankle',\n",
        "        'left_heel', 'right_heel',\n",
        "        'left_foot_index', 'right_foot_index',\n",
        "    ]\n",
        "\n",
        "  def __call__(self, landmarks):\n",
        "    \"\"\"Normalizes pose landmarks and converts to embedding\n",
        "    \n",
        "    Args:\n",
        "      landmarks - NumPy array with 3D landmarks of shape (N, 3).\n",
        "\n",
        "    Result:\n",
        "      Numpy array with pose embedding of shape (M, 3) where `M` is the number of\n",
        "      pairwise distances defined in `_get_pose_distance_embedding`.\n",
        "    \"\"\"\n",
        "    assert landmarks.shape[0] == len(self._landmark_names), 'Unexpected number of landmarks: {}'.format(landmarks.shape[0])\n",
        "\n",
        "    # Get pose landmarks.\n",
        "    landmarks = np.copy(landmarks)\n",
        "\n",
        "    # Normalize landmarks.\n",
        "    landmarks = self._normalize_pose_landmarks(landmarks)\n",
        "\n",
        "    # Get embedding.\n",
        "    embedding = self._get_pose_distance_embedding(landmarks)\n",
        "\n",
        "    return embedding\n",
        "\n",
        "  def _normalize_pose_landmarks(self, landmarks):\n",
        "    \"\"\"Normalizes landmarks translation and scale.\"\"\"\n",
        "    landmarks = np.copy(landmarks)\n",
        "\n",
        "    # Normalize translation.\n",
        "    pose_center = self._get_pose_center(landmarks)\n",
        "    landmarks -= pose_center\n",
        "\n",
        "    # Normalize scale.\n",
        "    pose_size = self._get_pose_size(landmarks, self._torso_size_multiplier)\n",
        "    landmarks /= pose_size\n",
        "    # Multiplication by 100 is not required, but makes it eaasier to debug.\n",
        "    landmarks *= 100\n",
        "\n",
        "    return landmarks\n",
        "\n",
        "  def _get_pose_center(self, landmarks):\n",
        "    \"\"\"Calculates pose center as point between hips.\"\"\"\n",
        "    left_hip = landmarks[self._landmark_names.index('left_hip')]\n",
        "    right_hip = landmarks[self._landmark_names.index('right_hip')]\n",
        "    center = (left_hip + right_hip) * 0.5\n",
        "    return center\n",
        "\n",
        "  def _get_pose_size(self, landmarks, torso_size_multiplier):\n",
        "    \"\"\"Calculates pose size.\n",
        "    \n",
        "    It is the maximum of two values:\n",
        "      * Torso size multiplied by `torso_size_multiplier`\n",
        "      * Maximum distance from pose center to any pose landmark\n",
        "    \"\"\"\n",
        "    # This approach uses only 2D landmarks to compute pose size.\n",
        "    landmarks = landmarks[:, :2]\n",
        "\n",
        "    # Hips center.\n",
        "    left_hip = landmarks[self._landmark_names.index('left_hip')]\n",
        "    right_hip = landmarks[self._landmark_names.index('right_hip')]\n",
        "    hips = (left_hip + right_hip) * 0.5\n",
        "\n",
        "    # Shoulders center.\n",
        "    left_shoulder = landmarks[self._landmark_names.index('left_shoulder')]\n",
        "    right_shoulder = landmarks[self._landmark_names.index('right_shoulder')]\n",
        "    shoulders = (left_shoulder + right_shoulder) * 0.5\n",
        "\n",
        "    # Torso size as the minimum body size.\n",
        "    torso_size = np.linalg.norm(shoulders - hips)\n",
        "\n",
        "    # Max dist to pose center.\n",
        "    pose_center = self._get_pose_center(landmarks)\n",
        "    max_dist = np.max(np.linalg.norm(landmarks - pose_center, axis=1))\n",
        "\n",
        "    return max(torso_size * torso_size_multiplier, max_dist)\n",
        "\n",
        "  def _get_pose_distance_embedding(self, landmarks):\n",
        "    \"\"\"Converts pose landmarks into 3D embedding.\n",
        "\n",
        "    We use several pairwise 3D distances to form pose embedding. All distances\n",
        "    include X and Y components with sign. We differnt types of pairs to cover\n",
        "    different pose classes. Feel free to remove some or add new.\n",
        "    \n",
        "    Args:\n",
        "      landmarks - NumPy array with 3D landmarks of shape (N, 3).\n",
        "\n",
        "    Result:\n",
        "      Numpy array with pose embedding of shape (M, 3) where `M` is the number of\n",
        "      pairwise distances.\n",
        "    \"\"\"\n",
        "    embedding = np.array([\n",
        "        # One joint.\n",
        "\n",
        "        self._get_distance(\n",
        "            self._get_average_by_names(landmarks, 'left_hip', 'right_hip'),\n",
        "            self._get_average_by_names(landmarks, 'left_shoulder', 'right_shoulder')),\n",
        "\n",
        "        self._get_distance_by_names(landmarks, 'left_shoulder', 'left_elbow'),\n",
        "        self._get_distance_by_names(landmarks, 'right_shoulder', 'right_elbow'),\n",
        "\n",
        "        self._get_distance_by_names(landmarks, 'left_elbow', 'left_wrist'),\n",
        "        self._get_distance_by_names(landmarks, 'right_elbow', 'right_wrist'),\n",
        "\n",
        "        self._get_distance_by_names(landmarks, 'left_hip', 'left_knee'),\n",
        "        self._get_distance_by_names(landmarks, 'right_hip', 'right_knee'),\n",
        "\n",
        "        self._get_distance_by_names(landmarks, 'left_knee', 'left_ankle'),\n",
        "        self._get_distance_by_names(landmarks, 'right_knee', 'right_ankle'),\n",
        "\n",
        "        # Two joints.\n",
        "\n",
        "        self._get_distance_by_names(landmarks, 'left_shoulder', 'left_wrist'),\n",
        "        self._get_distance_by_names(landmarks, 'right_shoulder', 'right_wrist'),\n",
        "\n",
        "        self._get_distance_by_names(landmarks, 'left_hip', 'left_ankle'),\n",
        "        self._get_distance_by_names(landmarks, 'right_hip', 'right_ankle'),\n",
        "\n",
        "        # Four joints.\n",
        "\n",
        "        self._get_distance_by_names(landmarks, 'left_hip', 'left_wrist'),\n",
        "        self._get_distance_by_names(landmarks, 'right_hip', 'right_wrist'),\n",
        "\n",
        "        # Five joints.\n",
        "\n",
        "        self._get_distance_by_names(landmarks, 'left_shoulder', 'left_ankle'),\n",
        "        self._get_distance_by_names(landmarks, 'right_shoulder', 'right_ankle'),\n",
        "        \n",
        "        self._get_distance_by_names(landmarks, 'left_hip', 'left_wrist'),\n",
        "        self._get_distance_by_names(landmarks, 'right_hip', 'right_wrist'),\n",
        "\n",
        "        # Cross body.\n",
        "\n",
        "        self._get_distance_by_names(landmarks, 'left_elbow', 'right_elbow'),\n",
        "        self._get_distance_by_names(landmarks, 'left_knee', 'right_knee'),\n",
        "\n",
        "        self._get_distance_by_names(landmarks, 'left_wrist', 'right_wrist'),\n",
        "        self._get_distance_by_names(landmarks, 'left_ankle', 'right_ankle'),\n",
        "\n",
        "        # Body bent direction.\n",
        "\n",
        "        # self._get_distance(\n",
        "        #     self._get_average_by_names(landmarks, 'left_wrist', 'left_ankle'),\n",
        "        #     landmarks[self._landmark_names.index('left_hip')]),\n",
        "        # self._get_distance(\n",
        "        #     self._get_average_by_names(landmarks, 'right_wrist', 'right_ankle'),\n",
        "        #     landmarks[self._landmark_names.index('right_hip')]),\n",
        "    ])\n",
        "\n",
        "    return embedding\n",
        "\n",
        "  def _get_average_by_names(self, landmarks, name_from, name_to):\n",
        "    lmk_from = landmarks[self._landmark_names.index(name_from)]\n",
        "    lmk_to = landmarks[self._landmark_names.index(name_to)]\n",
        "    return (lmk_from + lmk_to) * 0.5\n",
        "\n",
        "  def _get_distance_by_names(self, landmarks, name_from, name_to):\n",
        "    lmk_from = landmarks[self._landmark_names.index(name_from)]\n",
        "    lmk_to = landmarks[self._landmark_names.index(name_to)]\n",
        "    return self._get_distance(lmk_from, lmk_to)\n",
        "\n",
        "  def _get_distance(self, lmk_from, lmk_to):\n",
        "    return lmk_to - lmk_from"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hH-efWS61Tfy"
      },
      "source": [
        "## Pose classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TR9M0uAK1WzX"
      },
      "source": [
        "class PoseSample(object):\n",
        "\n",
        "  def __init__(self, name, landmarks, class_name, embedding):\n",
        "    self.name = name\n",
        "    self.landmarks = landmarks\n",
        "    self.class_name = class_name\n",
        "    \n",
        "    self.embedding = embedding\n",
        "\n",
        "\n",
        "class PoseSampleOutlier(object):\n",
        "\n",
        "  def __init__(self, sample, detected_class, all_classes):\n",
        "    self.sample = sample\n",
        "    self.detected_class = detected_class\n",
        "    self.all_classes = all_classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y230jVvP1u33"
      },
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "class PoseClassifier(object):\n",
        "  \"\"\"Classifies pose landmarks.\"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               pose_samples_folder,\n",
        "               pose_embedder,\n",
        "               file_extension='csv',\n",
        "               file_separator=',',\n",
        "               n_landmarks=33,\n",
        "               n_dimensions=3,\n",
        "               top_n_by_max_distance=30,\n",
        "               top_n_by_mean_distance=10,\n",
        "               axes_weights=(1., 1., 0.2)):\n",
        "    self._pose_embedder = pose_embedder\n",
        "    self._n_landmarks = n_landmarks\n",
        "    self._n_dimensions = n_dimensions\n",
        "    self._top_n_by_max_distance = top_n_by_max_distance\n",
        "    self._top_n_by_mean_distance = top_n_by_mean_distance\n",
        "    self._axes_weights = axes_weights\n",
        "\n",
        "    self._pose_samples = self._load_pose_samples(pose_samples_folder,\n",
        "                                                 file_extension,\n",
        "                                                 file_separator,\n",
        "                                                 n_landmarks,\n",
        "                                                 n_dimensions,\n",
        "                                                 pose_embedder)\n",
        "\n",
        "  def _load_pose_samples(self,\n",
        "                         pose_samples_folder,\n",
        "                         file_extension,\n",
        "                         file_separator,\n",
        "                         n_landmarks,\n",
        "                         n_dimensions,\n",
        "                         pose_embedder):\n",
        "    \"\"\"Loads pose samples from a given folder.\n",
        "    \n",
        "    Required folder structure:\n",
        "      neutral_standing.csv\n",
        "      pushups_down.csv\n",
        "      pushups_up.csv\n",
        "      squats_down.csv\n",
        "      ...\n",
        "\n",
        "    Required CSV structure:\n",
        "      sample_00001,x1,y1,z1,x2,y2,z2,....\n",
        "      sample_00002,x1,y1,z1,x2,y2,z2,....\n",
        "      ...\n",
        "    \"\"\"\n",
        "    # Each file in the folder represents one pose class.\n",
        "    file_names = [name for name in os.listdir(pose_samples_folder) if name.endswith(file_extension)]\n",
        "\n",
        "    pose_samples = []\n",
        "    for file_name in file_names:\n",
        "      # Use file name as pose class name.\n",
        "      class_name = file_name[:-(len(file_extension) + 1)]\n",
        "      \n",
        "      # Parse CSV.\n",
        "      with open(os.path.join(pose_samples_folder, file_name)) as csv_file:\n",
        "        csv_reader = csv.reader(csv_file, delimiter=file_separator)\n",
        "        for row in csv_reader:\n",
        "          assert len(row) == n_landmarks * n_dimensions + 1, 'Wrong number of values: {}'.format(len(row))\n",
        "          landmarks = np.array(row[1:], np.float32).reshape([n_landmarks, n_dimensions])\n",
        "          pose_samples.append(PoseSample(\n",
        "              name=row[0],\n",
        "              landmarks=landmarks,\n",
        "              class_name=class_name,\n",
        "              embedding=pose_embedder(landmarks),\n",
        "          ))\n",
        "\n",
        "    return pose_samples\n",
        "\n",
        "  def find_pose_sample_outliers(self):\n",
        "    \"\"\"Classifies each sample against the entire database.\"\"\"\n",
        "    # Find outliers in target poses\n",
        "    outliers = []\n",
        "    for sample in self._pose_samples:\n",
        "      # Find nearest poses for the target one.\n",
        "      pose_landmarks = sample.landmarks.copy()\n",
        "      pose_classification = self.__call__(pose_landmarks)\n",
        "      class_names = [class_name for class_name, count in pose_classification.items() if count == max(pose_classification.values())]\n",
        "\n",
        "      # Sample is an outlier if nearest poses have different class or more than\n",
        "      # one pose class is detected as nearest.\n",
        "      if sample.class_name not in class_names or len(class_names) != 1:\n",
        "        outliers.append(PoseSampleOutlier(sample, class_names, pose_classification))\n",
        "\n",
        "    return outliers\n",
        "\n",
        "  def __call__(self, pose_landmarks):\n",
        "    \"\"\"Classifies given pose.\n",
        "\n",
        "    Classification is done in two stages:\n",
        "      * First we pick top-N samples by MAX distance. It allows to remove samples\n",
        "        that are almost the same as given pose, but has few joints bent in the\n",
        "        other direction.\n",
        "      * Then we pick top-N samples by MEAN distance. After outliers are removed\n",
        "        on a previous step, we can pick samples that are closes on average.\n",
        "    \n",
        "    Args:\n",
        "      pose_landmarks: NumPy array with 3D landmarks of shape (N, 3).\n",
        "\n",
        "    Returns:\n",
        "      Dictionary with count of nearest pose samples from the database. Sample:\n",
        "        {\n",
        "          'pushups_down': 8,\n",
        "          'pushups_up': 2,\n",
        "        }\n",
        "    \"\"\"\n",
        "    # Check that provided and target poses have the same shape.\n",
        "    assert pose_landmarks.shape == (self._n_landmarks, self._n_dimensions), 'Unexpected shape: {}'.format(pose_landmarks.shape)\n",
        "\n",
        "    # Get given pose embedding.\n",
        "    pose_embedding = self._pose_embedder(pose_landmarks)\n",
        "    flipped_pose_embedding = self._pose_embedder(pose_landmarks * np.array([-1, 1, 1]))\n",
        "\n",
        "    # Filter by max distance.\n",
        "    #\n",
        "    # That helps to remove outliers - poses that are almost the same as the\n",
        "    # given one, but has one joint bent into another direction and actually\n",
        "    # represnt a different pose class.\n",
        "    max_dist_heap = []\n",
        "    for sample_idx, sample in enumerate(self._pose_samples):\n",
        "      max_dist = min(\n",
        "          np.max(np.abs(sample.embedding - pose_embedding) * self._axes_weights),\n",
        "          np.max(np.abs(sample.embedding - flipped_pose_embedding) * self._axes_weights),\n",
        "      )\n",
        "      max_dist_heap.append([max_dist, sample_idx])\n",
        "\n",
        "    max_dist_heap = sorted(max_dist_heap, key=lambda x: x[0])\n",
        "    max_dist_heap = max_dist_heap[:self._top_n_by_max_distance]\n",
        "\n",
        "    # Filter by mean distance.\n",
        "    #\n",
        "    # After removing outliers we can find the nearest pose by mean distance.\n",
        "    mean_dist_heap = []\n",
        "    for _, sample_idx in max_dist_heap:\n",
        "      sample = self._pose_samples[sample_idx]\n",
        "      mean_dist = min(\n",
        "          np.mean(np.abs(sample.embedding - pose_embedding) * self._axes_weights),\n",
        "          np.mean(np.abs(sample.embedding - flipped_pose_embedding) * self._axes_weights),\n",
        "      )\n",
        "      mean_dist_heap.append([mean_dist, sample_idx])\n",
        "\n",
        "    mean_dist_heap = sorted(mean_dist_heap, key=lambda x: x[0])\n",
        "    mean_dist_heap = mean_dist_heap[:self._top_n_by_mean_distance]\n",
        "\n",
        "    # Collect results into map: (class_name -> n_samples)\n",
        "    class_names = [self._pose_samples[sample_idx].class_name for _, sample_idx in mean_dist_heap]\n",
        "    result = {class_name: class_names.count(class_name) for class_name in set(class_names)}\n",
        "\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-VRo98tE1JH"
      },
      "source": [
        "## Classification smoothing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POC4_eQsE3VO"
      },
      "source": [
        "class EMADictSmoothing(object):\n",
        "  \"\"\"Smoothes pose classification.\"\"\"\n",
        "\n",
        "  def __init__(self, window_size=10, alpha=0.2):\n",
        "    self._window_size = window_size\n",
        "    self._alpha = alpha\n",
        "\n",
        "    self._data_in_window = []\n",
        "\n",
        "  def __call__(self, data):\n",
        "    \"\"\"Smoothes given pose classification.\n",
        "\n",
        "    Smoothing is done by computing Exponential Moving Average for every pose\n",
        "    class observed in the given time window. Missed pose classes arre replaced\n",
        "    with 0.\n",
        "    \n",
        "    Args:\n",
        "      data: Dictionary with pose classification. Sample:\n",
        "          {\n",
        "            'pushups_down': 8,\n",
        "            'pushups_up': 2,\n",
        "          }\n",
        "\n",
        "    Result:\n",
        "      Dictionary in the same format but with smoothed and float instead of\n",
        "      integer values. Sample:\n",
        "        {\n",
        "          'pushups_down': 8.3,\n",
        "          'pushups_up': 1.7,\n",
        "        }\n",
        "    \"\"\"\n",
        "    # Add new data to the beginning of the window for simpler code.\n",
        "    self._data_in_window.insert(0, data)\n",
        "    self._data_in_window = self._data_in_window[:self._window_size]\n",
        "\n",
        "    # Get all keys.\n",
        "    keys = set([key for data in self._data_in_window for key, _ in data.items()])\n",
        "\n",
        "    # Get smoothed values.\n",
        "    smoothed_data = dict()\n",
        "    for key in keys:\n",
        "      factor = 1.0\n",
        "      top_sum = 0.0\n",
        "      bottom_sum = 0.0\n",
        "      for data in self._data_in_window:\n",
        "        value = data[key] if key in data else 0.0\n",
        "\n",
        "        top_sum += factor * value\n",
        "        bottom_sum += factor\n",
        "\n",
        "        # Update factor.\n",
        "        factor *= (1.0 - self._alpha)\n",
        "\n",
        "      smoothed_data[key] = top_sum / bottom_sum\n",
        "\n",
        "    return smoothed_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWuA2OYgGtZn"
      },
      "source": [
        "## Repetition counter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEs_lgNiGv-j"
      },
      "source": [
        "class RepetitionCounter(object):\n",
        "  \"\"\"Counts number of repetitions of given target pose class.\"\"\"\n",
        "\n",
        "  def __init__(self, class_name, enter_threshold=6, exit_threshold=4):\n",
        "    self._class_name = class_name\n",
        "\n",
        "    # If pose counter passes given threshold, then we enter the pose.\n",
        "    self._enter_threshold = enter_threshold\n",
        "    self._exit_threshold = exit_threshold\n",
        "\n",
        "    # Either we are in given pose or not.\n",
        "    self._pose_entered = False\n",
        "\n",
        "    # Number of times we exited the pose.\n",
        "    self._n_repeats = 0\n",
        "\n",
        "  @property\n",
        "  def n_repeats(self):\n",
        "    return self._n_repeats\n",
        "\n",
        "  def __call__(self, pose_classification):\n",
        "    \"\"\"Counts number of repetitions happend until given frame.\n",
        "\n",
        "    We use two thresholds. First you need to go above the higher one to enter\n",
        "    the pose, and then you need to go below the lower one to exit it. Difference\n",
        "    between the thresholds makes it stable to prediction jittering (which will\n",
        "    cause wrong counts in case of having only one threshold).\n",
        "    \n",
        "    Args:\n",
        "      pose_classification: Pose classification dictionary on current frame.\n",
        "        Sample:\n",
        "          {\n",
        "            'pushups_down': 8.3,\n",
        "            'pushups_up': 1.7,\n",
        "          }\n",
        "\n",
        "    Returns:\n",
        "      Integer counter of repetitions.\n",
        "    \"\"\"\n",
        "    # Get pose confidence.\n",
        "    pose_confidence = 0.0\n",
        "    if self._class_name in pose_classification:\n",
        "      pose_confidence = pose_classification[self._class_name]\n",
        "\n",
        "    # On the very first frame or if we were out of the pose, just check if we\n",
        "    # entered it on this frame and update the state.\n",
        "    if not self._pose_entered:\n",
        "      self._pose_entered = pose_confidence > self._enter_threshold\n",
        "      return self._n_repeats\n",
        "\n",
        "    # If we were in the pose and are exiting it, then increase the counter and\n",
        "    # update the state.\n",
        "    if pose_confidence < self._exit_threshold:\n",
        "      self._n_repeats += 1\n",
        "      self._pose_entered = False\n",
        "\n",
        "    return self._n_repeats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBVyanN2Ic4W"
      },
      "source": [
        "## Classification visualizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgFLe1oTIgJH"
      },
      "source": [
        "import io\n",
        "from PIL import Image\n",
        "from PIL import ImageFont\n",
        "from PIL import ImageDraw\n",
        "import requests\n",
        "\n",
        "class PoseClassificationVisualizer(object):\n",
        "  \"\"\"Keeps track of claassifcations for every frame and renders them.\"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               class_name,\n",
        "               plot_location_x=0.05,\n",
        "               plot_location_y=0.05,\n",
        "               plot_max_width=0.4,\n",
        "               plot_max_height=0.4,\n",
        "               plot_figsize=(9, 4),\n",
        "               plot_x_max=None,\n",
        "               plot_y_max=None,\n",
        "               counter_location_x=0.85,\n",
        "               counter_location_y=0.05,\n",
        "               counter_font_path='https://github.com/googlefonts/roboto/blob/main/src/hinted/Roboto-Regular.ttf?raw=true',\n",
        "               counter_font_color='red',\n",
        "               counter_font_size=0.15):\n",
        "    self._class_name = class_name\n",
        "    self._plot_location_x = plot_location_x\n",
        "    self._plot_location_y = plot_location_y\n",
        "    self._plot_max_width = plot_max_width\n",
        "    self._plot_max_height = plot_max_height\n",
        "    self._plot_figsize = plot_figsize\n",
        "    self._plot_x_max = plot_x_max\n",
        "    self._plot_y_max = plot_y_max\n",
        "    self._counter_location_x = counter_location_x\n",
        "    self._counter_location_y = counter_location_y\n",
        "    self._counter_font_path = counter_font_path\n",
        "    self._counter_font_color = counter_font_color\n",
        "    self._counter_font_size = counter_font_size\n",
        "\n",
        "    self._counter_font = None\n",
        "\n",
        "    self._pose_classification_history = []\n",
        "    self._pose_classification_filtered_history = []\n",
        "\n",
        "  def __call__(self,\n",
        "               frame,\n",
        "               pose_classification,\n",
        "               pose_classification_filtered,\n",
        "               repetitions_count):\n",
        "    \"\"\"Renders pose classifcation and counter until given frame.\"\"\"\n",
        "    # Extend classification history.\n",
        "    self._pose_classification_history.append(pose_classification)\n",
        "    self._pose_classification_filtered_history.append(pose_classification_filtered)\n",
        "\n",
        "    # Output frame with classification plot and counter.\n",
        "    output_img = Image.fromarray(frame)\n",
        "\n",
        "    output_width = output_img.size[0]\n",
        "    output_height = output_img.size[1]\n",
        "\n",
        "    # Draw the plot.\n",
        "    img = self._plot_classification_history(output_width, output_height)\n",
        "    img.thumbnail((int(output_width * self._plot_max_width),\n",
        "                   int(output_height * self._plot_max_height)),\n",
        "                  Image.ANTIALIAS)\n",
        "    output_img.paste(img,\n",
        "                     (int(output_width * self._plot_location_x),\n",
        "                      int(output_height * self._plot_location_y)))\n",
        "\n",
        "    # Draw the count.\n",
        "    output_img_draw = ImageDraw.Draw(output_img)\n",
        "    if self._counter_font is None:\n",
        "      font_size = int(output_height * self._counter_font_size)\n",
        "      font_request = requests.get(self._counter_font_path, allow_redirects=True)\n",
        "      self._counter_font = ImageFont.truetype(io.BytesIO(font_request.content), size=font_size)\n",
        "    output_img_draw.text((output_width * self._counter_location_x,\n",
        "                          output_height * self._counter_location_y),\n",
        "                         str(repetitions_count),\n",
        "                         font=self._counter_font,\n",
        "                         fill=self._counter_font_color)\n",
        "\n",
        "    return output_img\n",
        "\n",
        "  def _plot_classification_history(self, output_width, output_height):\n",
        "    fig = plt.figure(figsize=self._plot_figsize)\n",
        "\n",
        "    for classification_history in [self._pose_classification_history,\n",
        "                                   self._pose_classification_filtered_history]:\n",
        "      y = []\n",
        "      for classification in classification_history:\n",
        "        if classification is None:\n",
        "          y.append(None)\n",
        "        elif self._class_name in classification:\n",
        "          y.append(classification[self._class_name])\n",
        "        else:\n",
        "          y.append(0)\n",
        "      plt.plot(y, linewidth=7)\n",
        "\n",
        "    plt.grid(axis='y', alpha=0.75)\n",
        "    plt.xlabel('Frame')\n",
        "    plt.ylabel('Confidence')\n",
        "    plt.title('Classification history for `{}`'.format(self._class_name))\n",
        "    plt.legend(loc='upper right')\n",
        "\n",
        "    if self._plot_y_max is not None:\n",
        "      plt.ylim(top=self._plot_y_max)\n",
        "    if self._plot_x_max is not None:\n",
        "      plt.xlim(right=self._plot_x_max)\n",
        "\n",
        "    # Convert plot to image.\n",
        "    buf = io.BytesIO()\n",
        "    dpi = min(\n",
        "        output_width * self._plot_max_width / float(self._plot_figsize[0]),\n",
        "        output_height * self._plot_max_height / float(self._plot_figsize[1]))\n",
        "    fig.savefig(buf, dpi=dpi)\n",
        "    buf.seek(0)\n",
        "    img = Image.open(buf)\n",
        "    plt.close()\n",
        "\n",
        "    return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlUbZ_c-Aq4B"
      },
      "source": [
        "## Bootstrap helper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tw2xYlGmAt3q"
      },
      "source": [
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "import sys\n",
        "import tqdm\n",
        "\n",
        "from mediapipe.python.solutions import drawing_utils as mp_drawing\n",
        "from mediapipe.python.solutions import pose as mp_pose\n",
        "\n",
        "\n",
        "class BootstrapHelper(object):\n",
        "  \"\"\"Helps to bootstrap images and filter pose samples for classification.\"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               images_in_folder,\n",
        "               images_out_folder,\n",
        "               csvs_out_folder):\n",
        "    self._images_in_folder = images_in_folder\n",
        "    self._images_out_folder = images_out_folder\n",
        "    self._csvs_out_folder = csvs_out_folder\n",
        "\n",
        "    # Get list of pose classes and print image statistics.\n",
        "    self._pose_class_names = sorted([n for n in os.listdir(self._images_in_folder) if not n.startswith('.')])\n",
        "    \n",
        "  def bootstrap(self, per_pose_class_limit=None):\n",
        "    \"\"\"Bootstraps images in a given folder.\n",
        "    \n",
        "    Required image in folder (same use for image out folder):\n",
        "      pushups_up/\n",
        "        image_001.jpg\n",
        "        image_002.jpg\n",
        "        ...\n",
        "      pushups_down/\n",
        "        image_001.jpg\n",
        "        image_002.jpg\n",
        "        ...\n",
        "      ...\n",
        "\n",
        "    Produced CSVs out folder:\n",
        "      pushups_up.csv\n",
        "      pushups_down.csv\n",
        "\n",
        "    Produced CSV structure with pose 3D landmarks:\n",
        "      sample_00001,x1,y1,z1,x2,y2,z2,....\n",
        "      sample_00002,x1,y1,z1,x2,y2,z2,....\n",
        "    \"\"\"\n",
        "    # Create output folder for CVSs.\n",
        "    if not os.path.exists(self._csvs_out_folder):\n",
        "      os.makedirs(self._csvs_out_folder)\n",
        "\n",
        "    for pose_class_name in self._pose_class_names:\n",
        "      print('Bootstrapping ', pose_class_name, file=sys.stderr)\n",
        "\n",
        "      # Paths for the pose class.\n",
        "      images_in_folder = os.path.join(self._images_in_folder, pose_class_name)\n",
        "      images_out_folder = os.path.join(self._images_out_folder, pose_class_name)\n",
        "      csv_out_path = os.path.join(self._csvs_out_folder, pose_class_name + '.csv')\n",
        "      if not os.path.exists(images_out_folder):\n",
        "        os.makedirs(images_out_folder)\n",
        "\n",
        "      with open(csv_out_path, 'w') as csv_out_file:\n",
        "        csv_out_writer = csv.writer(csv_out_file, delimiter=',', quoting=csv.QUOTE_MINIMAL)\n",
        "        # Get list of images.\n",
        "        image_names = sorted([n for n in os.listdir(images_in_folder) if not n.startswith('.')])\n",
        "        if per_pose_class_limit is not None:\n",
        "          image_names = image_names[:per_pose_class_limit]\n",
        "\n",
        "        # Bootstrap every image.\n",
        "        for image_name in tqdm.tqdm(image_names):\n",
        "          # Load image.\n",
        "          input_frame = cv2.imread(os.path.join(images_in_folder, image_name))\n",
        "          input_frame = cv2.cvtColor(input_frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "          # Initialize fresh pose tracker and run it.\n",
        "          with mp_pose.Pose(upper_body_only=False) as pose_tracker:\n",
        "            result = pose_tracker.process(image=input_frame)\n",
        "            pose_landmarks = result.pose_landmarks\n",
        "\n",
        "          # Save image with pose prediction (if pose was detected).\n",
        "          output_frame = input_frame.copy()\n",
        "          if pose_landmarks is not None:\n",
        "            mp_drawing.draw_landmarks(\n",
        "                image=output_frame,\n",
        "                landmark_list=pose_landmarks,\n",
        "                connections=mp_pose.POSE_CONNECTIONS)\n",
        "          output_frame = cv2.cvtColor(output_frame, cv2.COLOR_RGB2BGR)\n",
        "          cv2.imwrite(os.path.join(images_out_folder, image_name), output_frame)\n",
        "          \n",
        "          # Save landmarks if pose was detected.\n",
        "          if pose_landmarks is not None:\n",
        "            # Get landmarks.\n",
        "            frame_height, frame_width = output_frame.shape[0], output_frame.shape[1]\n",
        "            pose_landmarks = np.array(\n",
        "                [[lmk.x * frame_width, lmk.y * frame_height, lmk.z * frame_width]\n",
        "                 for lmk in pose_landmarks.landmark],\n",
        "                dtype=np.float32)\n",
        "            assert pose_landmarks.shape == (33, 3), 'Unexpected landmarks shape: {}'.format(pose_landmarks.shape)\n",
        "            csv_out_writer.writerow([image_name] + pose_landmarks.flatten().astype(np.str).tolist())\n",
        "\n",
        "          # Draw XZ projection and concatenate with the image.\n",
        "          projection_xz = self._draw_xz_projection(\n",
        "              output_frame=output_frame, pose_landmarks=pose_landmarks)\n",
        "          output_frame = np.concatenate((output_frame, projection_xz), axis=1)\n",
        "\n",
        "  def _draw_xz_projection(self, output_frame, pose_landmarks, r=0.5, color='red'):\n",
        "    frame_height, frame_width = output_frame.shape[0], output_frame.shape[1]\n",
        "    img = Image.new('RGB', (frame_width, frame_height), color='white')\n",
        "\n",
        "    if pose_landmarks is None:\n",
        "      return np.asarray(img)\n",
        "\n",
        "    # Scale radius according to the image width.\n",
        "    r *= frame_width * 0.01\n",
        "\n",
        "    draw = ImageDraw.Draw(img)\n",
        "    for idx_1, idx_2 in mp_pose.POSE_CONNECTIONS:\n",
        "      # Flip Z and move hips center to the center of the image.\n",
        "      x1, y1, z1 = pose_landmarks[idx_1] * [1, 1, -1] + [0, 0, frame_height * 0.5]\n",
        "      x2, y2, z2 = pose_landmarks[idx_2] * [1, 1, -1] + [0, 0, frame_height * 0.5]\n",
        "\n",
        "      draw.ellipse([x1 - r, z1 - r, x1 + r, z1 + r], fill=color)\n",
        "      draw.ellipse([x2 - r, z2 - r, x2 + r, z2 + r], fill=color)\n",
        "      draw.line([x1, z1, x2, z2], width=int(r), fill=color)\n",
        "\n",
        "    return np.asarray(img)\n",
        "\n",
        "  def align_images_and_csvs(self, print_removed_items=False):\n",
        "    \"\"\"Makes sure that image folders and CSVs have the same sample.\n",
        "    \n",
        "    Leaves only intersetion of samples in both image folders and CSVs.\n",
        "    \"\"\"\n",
        "    for pose_class_name in self._pose_class_names:\n",
        "      # Paths for the pose class.\n",
        "      images_out_folder = os.path.join(self._images_out_folder, pose_class_name)\n",
        "      csv_out_path = os.path.join(self._csvs_out_folder, pose_class_name + '.csv')\n",
        "\n",
        "      # Read CSV into memory.\n",
        "      rows = []\n",
        "      with open(csv_out_path) as csv_out_file:\n",
        "        csv_out_reader = csv.reader(csv_out_file, delimiter=',')\n",
        "        for row in csv_out_reader:\n",
        "          rows.append(row)\n",
        "\n",
        "      # Image names left in CSV.\n",
        "      image_names_in_csv = []\n",
        "\n",
        "      # Re-write the CSV removing lines without corresponding images.\n",
        "      with open(csv_out_path, 'w') as csv_out_file:\n",
        "        csv_out_writer = csv.writer(csv_out_file, delimiter=',', quoting=csv.QUOTE_MINIMAL)\n",
        "        for row in rows:\n",
        "          image_name = row[0]\n",
        "          image_path = os.path.join(images_out_folder, image_name)\n",
        "          if os.path.exists(image_path):\n",
        "            image_names_in_csv.append(image_name)\n",
        "            csv_out_writer.writerow(row)\n",
        "          elif print_removed_items:\n",
        "            print('Removed image from CSV: ', image_path)\n",
        "\n",
        "      # Remove images without corresponding line in CSV.\n",
        "      for image_name in os.listdir(images_out_folder):\n",
        "        if image_name not in image_names_in_csv:\n",
        "          image_path = os.path.join(images_out_folder, image_name)\n",
        "          os.remove(image_path)\n",
        "          if print_removed_items:\n",
        "            print('Removed image from folder: ', image_path)\n",
        "\n",
        "  def analyze_outliers(self, outliers):\n",
        "    \"\"\"Classifies each sample agains all other to find outliers.\n",
        "    \n",
        "    If sample is classified differrrently than the original class - it sould\n",
        "    either be deleted or more similar samples should be aadded.\n",
        "    \"\"\"\n",
        "    for outlier in outliers:\n",
        "      image_path = os.path.join(self._images_out_folder, outlier.sample.class_name, outlier.sample.name)\n",
        "\n",
        "      print('Outlier')\n",
        "      print('  sample path =    ', image_path)\n",
        "      print('  sample class =   ', outlier.sample.class_name)\n",
        "      print('  detected class = ', outlier.detected_class)\n",
        "      print('  all classes =    ', outlier.all_classes)\n",
        "\n",
        "      img = cv2.imread(image_path)\n",
        "      img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "      show_image(img, figsize=(20, 20))\n",
        "\n",
        "  def remove_outliers(self, outliers):\n",
        "    \"\"\"Removes outliers from the image folders.\"\"\"\n",
        "    for outlier in outliers:\n",
        "      image_path = os.path.join(self._images_out_folder, outlier.sample.class_name, outlier.sample.name)\n",
        "      os.remove(image_path)\n",
        "\n",
        "  def print_images_in_statistics(self):\n",
        "    \"\"\"Prints statistics from the input image folder.\"\"\"\n",
        "    self._print_images_statistics(self._images_in_folder, self._pose_class_names)\n",
        "\n",
        "  def print_images_out_statistics(self):\n",
        "    \"\"\"Prints statistics from the output image folder.\"\"\"\n",
        "    self._print_images_statistics(self._images_out_folder, self._pose_class_names)\n",
        "\n",
        "  def _print_images_statistics(self, images_folder, pose_class_names):\n",
        "    print('Number of images per pose class:')\n",
        "    for pose_class_name in pose_class_names:\n",
        "      n_images = len([\n",
        "          n for n in os.listdir(os.path.join(images_folder, pose_class_name))\n",
        "          if not n.startswith('.')])\n",
        "      print('  {}: {}'.format(pose_class_name, n_images))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIiEj8Tx_x-q"
      },
      "source": [
        "# Step 1: Build classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpRszzilECFz"
      },
      "source": [
        "## Upload image samples\n",
        "\n",
        "Locally create a folder named `fitness_poses_images_in` with image samples.\n",
        "\n",
        "Images should repesent terminal states of desired pose classes. I.e. if you want to classify push-up provide iamges for two classes: when person is up, and when person is down.\n",
        "\n",
        "There should be about a few hundred samples per class covering different camera angles, environment conditions, body shapes, and exercise variations to build a good classifier.\n",
        "\n",
        "Required structure of the images_in_folder:\n",
        "```\n",
        "fitness_poses_images_in/\n",
        "  pushups_up/\n",
        "    image_001.jpg\n",
        "    image_002.jpg\n",
        "    ...\n",
        "  pushups_down/\n",
        "    image_001.jpg\n",
        "    image_002.jpg\n",
        "    ...\n",
        "  ...\n",
        "```\n",
        "\n",
        "Zip the `fitness_poses_images_in` folder:\n",
        "```\n",
        "zip -r fitness_poses_images_in.zip fitness_poses_images_in\n",
        "```\n",
        "\n",
        "And run the code below to upload it to the Colab runtime"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/drive/MyDrive/GRSS_SupCom/TRAIN.zip /content/drive/MyDrive/GRSS_SupCom/TRAIN"
      ],
      "metadata": {
        "id": "G_E2gMvc2Vjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DErZEmKUEDK0",
        "outputId": "9fd8dd60-e40b-4663-e75b-95ac540eb43d",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "uploaded = files.upload()\n",
        "os.listdir('.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-989abcc9-7eb3-465f-8cef-64ff2ccb5d7d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-989abcc9-7eb3-465f-8cef-64ff2ccb5d7d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TRAIN.zip to TRAIN.zip\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config', 'TRAIN.zip', 'drive', 'sample_data']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtTCrVF9EQZd"
      },
      "source": [
        "Unzip the archive:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwMkvJ1EEQ6b",
        "outputId": "3fa09c86-08af-4510-9b1f-2e15b7f6d25d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import zipfile\n",
        "import io\n",
        "\n",
        "zf = zipfile.ZipFile(io.BytesIO(uploaded['TRAIN.zip']), \"r\")\n",
        "zf.extractall()\n",
        "os.listdir('.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config', 'content', 'TRAIN.zip', 'drive', 'sample_data']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QBS_P_Y_2mg"
      },
      "source": [
        "## Bootstrap images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bERVPO8Ja6j7"
      },
      "source": [
        "# Required structure of the images_in_folder:\n",
        "#\n",
        "#   fitness_poses_images_in/\n",
        "#     pushups_up/\n",
        "#       image_001.jpg\n",
        "#       image_002.jpg\n",
        "#       ...\n",
        "#     pushups_down/\n",
        "#       image_001.jpg\n",
        "#       image_002.jpg\n",
        "#       ...\n",
        "#     ...\n",
        "bootstrap_images_in_folder = '/content/drive/MyDrive/GRSS_SupCom/TRAIN'\n",
        "\n",
        "# Output folders for bootstrapped images and CSVs.\n",
        "bootstrap_images_out_folder = '/content/drive/MyDrive/GRSS_SupCom/TRAIN_out'\n",
        "bootstrap_csvs_out_folder = 'yoga_poses_csvs_out'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVYsbbJbOW7W"
      },
      "source": [
        "# Initialize helper.\n",
        "bootstrap_helper = BootstrapHelper(\n",
        "    images_in_folder=bootstrap_images_in_folder,\n",
        "    images_out_folder=bootstrap_images_out_folder,\n",
        "    csvs_out_folder=bootstrap_csvs_out_folder,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e832H-X6b-v7",
        "outputId": "1443d79c-1d8e-4083-e4fb-07e5a899638e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Check how many pose classes and images for them are available.\n",
        "bootstrap_helper.print_images_in_statistics()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images per pose class:\n",
            "  downdog: 223\n",
            "  goddess: 180\n",
            "  plank: 266\n",
            "  tree: 160\n",
            "  warrior2: 252\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAWtcZSHcQHc",
        "outputId": "0c2ff6cb-2e38-49e3-e7be-5f140e623cff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Bootstrap all images.\n",
        "# Set limit to some small number for debug.\n",
        "bootstrap_helper.bootstrap(per_pose_class_limit=None)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Bootstrapping  downdog\n",
            "100%|██████████| 223/223 [02:51<00:00,  1.30it/s]\n",
            "Bootstrapping  goddess\n",
            "100%|██████████| 180/180 [02:05<00:00,  1.43it/s]\n",
            "Bootstrapping  plank\n",
            "100%|██████████| 266/266 [03:37<00:00,  1.22it/s]\n",
            "Bootstrapping  tree\n",
            "100%|██████████| 160/160 [02:06<00:00,  1.27it/s]\n",
            "Bootstrapping  warrior2\n",
            "100%|██████████| 252/252 [03:14<00:00,  1.30it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRdqXeUScko9",
        "outputId": "6a12ab46-afbd-4b33-f657-b337e4b022ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Check how many images were bootstrapped.\n",
        "bootstrap_helper.print_images_out_statistics()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images per pose class:\n",
            "  downdog: 223\n",
            "  goddess: 180\n",
            "  plank: 266\n",
            "  tree: 160\n",
            "  warrior2: 252\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTc3dlvFgg50",
        "outputId": "3b3d1699-19c1-493f-b3eb-b346a94771e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# After initial bootstrapping images without detected poses were still saved in\n",
        "# the folderd (but not in the CSVs) for debug purpose. Let's remove them.\n",
        "bootstrap_helper.align_images_and_csvs(print_removed_items=False)\n",
        "bootstrap_helper.print_images_out_statistics()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images per pose class:\n",
            "  downdog: 205\n",
            "  goddess: 170\n",
            "  plank: 261\n",
            "  tree: 153\n",
            "  warrior2: 245\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3Sjl9JcJQzN"
      },
      "source": [
        "## Manual filtration\n",
        "\n",
        "Please manually verify predictions and remove samples (images) that has wrong pose prediction. Check as if you were asked to classify pose just from predicted landmarks. If you can't - remove it.\n",
        "\n",
        "Align CSVs and image folders once you are done."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fI7OytDZiHmg",
        "outputId": "965e3e89-91f3-459d-feac-beb8a753568d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Align CSVs with filtered images.\n",
        "bootstrap_helper.align_images_and_csvs(print_removed_items=False)\n",
        "bootstrap_helper.print_images_out_statistics()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images per pose class:\n",
            "  downdog: 205\n",
            "  goddess: 170\n",
            "  plank: 261\n",
            "  tree: 153\n",
            "  warrior2: 245\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGxcMoDLK8L0"
      },
      "source": [
        "## Automatic filtration\n",
        "\n",
        "Classify each sample against database of all other samples and check if it gets in the same class as annotated after classification.\n",
        "\n",
        "There can be two reasons for the outliers:\n",
        "\n",
        "  * **Wrong pose prediction**: In this case remove such outliers.\n",
        "\n",
        "  * **Wrong classification** (i.e. pose is predicted correctly and you aggree with original pose class assigned to the sample): In this case sample is from the underrepresented group (e.g. unusual angle or just very few samples). Add more similar samples and run bootstrapping from the very beginning.\n",
        "\n",
        "Even if you just removed some samples it makes sence to re-run automatic filtration one more time as database of poses has changed.\n",
        "\n",
        "**Important!!** Check that you are using the same parameters when classifying whole videos later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txnkReCiJr4Y",
        "outputId": "7223abfc-8ce5-482a-9077-54f4a2eedf3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Find outliers.\n",
        "\n",
        "# Transforms pose landmarks into embedding.\n",
        "pose_embedder = FullBodyPoseEmbedder()\n",
        "\n",
        "# Classifies give pose against database of poses.\n",
        "pose_classifier = PoseClassifier(\n",
        "    pose_samples_folder=bootstrap_csvs_out_folder,\n",
        "    pose_embedder=pose_embedder,\n",
        "    top_n_by_max_distance=30,\n",
        "    top_n_by_mean_distance=10)\n",
        "\n",
        "outliers = pose_classifier.find_pose_sample_outliers()\n",
        "print('Number of outliers: ', len(outliers))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of outliers:  78\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyze outliers.\n",
        "bootstrap_helper.analyze_outliers(outliers)\n"
      ],
      "metadata": {
        "id": "NrMB1XD_1d2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip uninstall matplotlib\n",
        "!pip install matplotlib==3.1.3"
      ],
      "metadata": {
        "id": "KyJUetSKB9Gt",
        "outputId": "6ad320ca-b52d-486b-c1aa-1ef1b812157c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: matplotlib 3.3.4\n",
            "Uninstalling matplotlib-3.3.4:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.7/dist-packages/matplotlib-3.3.4-py3.7-nspkg.pth\n",
            "    /usr/local/lib/python3.7/dist-packages/matplotlib-3.3.4.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/matplotlib/*\n",
            "    /usr/local/lib/python3.7/dist-packages/mpl_toolkits/axes_grid/*\n",
            "    /usr/local/lib/python3.7/dist-packages/mpl_toolkits/axes_grid1/*\n",
            "    /usr/local/lib/python3.7/dist-packages/mpl_toolkits/axisartist/*\n",
            "    /usr/local/lib/python3.7/dist-packages/mpl_toolkits/mplot3d/*\n",
            "    /usr/local/lib/python3.7/dist-packages/mpl_toolkits/tests/*\n",
            "    /usr/local/lib/python3.7/dist-packages/pylab.py\n",
            "Proceed (y/n)? "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTWgo8-rlDFv"
      },
      "source": [
        "# Remove all outliers (if you don't want to manually pick).\n",
        "bootstrap_helper.remove_outliers(outliers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LR9xOhPdlrkN",
        "outputId": "c9a2e1dc-971a-46b9-8334-f5fe8c96223a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Align CSVs with images after removing outliers.\n",
        "bootstrap_helper.align_images_and_csvs(print_removed_items=False)\n",
        "bootstrap_helper.print_images_out_statistics()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images per pose class:\n",
            "  downdog: 193\n",
            "  goddess: 138\n",
            "  plank: 250\n",
            "  tree: 149\n",
            "  warrior2: 226\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nd0OSLWXMJFC"
      },
      "source": [
        "## Dump for the App\n",
        "\n",
        "Dump filtered poses to CSV and download it.\n",
        "\n",
        "Please check this [guide](https://developers.google.com/ml-kit/vision/pose-detection/classifying-poses#4_integrate_with_the_ml_kit_quickstart_app) on how to use this CSV in the ML Kit sample app."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2VfIiLPML8A",
        "outputId": "d001b613-7121-4e0c-ce15-3415733c7932",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "import csv\n",
        "import os\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "\n",
        "def dump_for_the_app():\n",
        "  pose_samples_folder = 'yoga_poses_csvs_out'\n",
        "  pose_samples_csv_path = 'yoga_poses_csvs_out.csv'\n",
        "  file_extension = 'csv'\n",
        "  file_separator = ','\n",
        "\n",
        "  # Each file in the folder represents one pose class.\n",
        "  file_names = [name for name in os.listdir(pose_samples_folder) if name.endswith(file_extension)]\n",
        "\n",
        "  with open(pose_samples_csv_path, 'w') as csv_out:\n",
        "    csv_out_writer = csv.writer(csv_out, delimiter=file_separator, quoting=csv.QUOTE_MINIMAL)\n",
        "    for file_name in file_names:\n",
        "      # Use file name as pose class name.\n",
        "      class_name = file_name[:-(len(file_extension) + 1)]\n",
        "\n",
        "      # One file line: `sample_00001,x1,y1,x2,y2,....`.\n",
        "      with open(os.path.join(pose_samples_folder, file_name)) as csv_in:\n",
        "        csv_in_reader = csv.reader(csv_in, delimiter=file_separator)\n",
        "        for row in csv_in_reader:\n",
        "          row.insert(1, class_name)\n",
        "          csv_out_writer.writerow(row)\n",
        "\n",
        "  files.download(pose_samples_csv_path)\n",
        "\n",
        "\n",
        "dump_for_the_app()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_85c565f6-a59e-471d-8926-edf7e018ea5e\", \"yoga_poses_csvs_out.csv\", 954970)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data=pd.read_csv('/content/yoga_poses_csvs_out.csv')\n",
        "data.head()"
      ],
      "metadata": {
        "id": "vQ3FT--4C3r2",
        "outputId": "591c8c6a-71bb-42b1-f536-8e4d54cf5368",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e0423dac-9211-41cf-a736-1de352035cb1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>00000070.jpg</th>\n",
              "      <th>tree</th>\n",
              "      <th>347.6777</th>\n",
              "      <th>208.47787</th>\n",
              "      <th>1.7534643</th>\n",
              "      <th>343.44107</th>\n",
              "      <th>203.45293</th>\n",
              "      <th>-13.967356</th>\n",
              "      <th>340.44415</th>\n",
              "      <th>204.14412</th>\n",
              "      <th>-13.867795</th>\n",
              "      <th>337.5879</th>\n",
              "      <th>204.89993</th>\n",
              "      <th>-14.017029</th>\n",
              "      <th>351.0037</th>\n",
              "      <th>202.52408</th>\n",
              "      <th>-17.953999</th>\n",
              "      <th>353.52408</th>\n",
              "      <th>201.96614</th>\n",
              "      <th>-17.729898</th>\n",
              "      <th>356.13348</th>\n",
              "      <th>201.59767</th>\n",
              "      <th>-17.693254</th>\n",
              "      <th>333.7885</th>\n",
              "      <th>213.2921</th>\n",
              "      <th>-58.583916</th>\n",
              "      <th>359.61234</th>\n",
              "      <th>207.5689</th>\n",
              "      <th>-75.20829</th>\n",
              "      <th>344.51147</th>\n",
              "      <th>217.86407</th>\n",
              "      <th>-10.804385</th>\n",
              "      <th>351.86786</th>\n",
              "      <th>216.06653</th>\n",
              "      <th>-14.848616</th>\n",
              "      <th>313.2885</th>\n",
              "      <th>254.73726</th>\n",
              "      <th>-59.65417</th>\n",
              "      <th>384.0316</th>\n",
              "      <th>246.03201</th>\n",
              "      <th>...</th>\n",
              "      <th>-74.393326</th>\n",
              "      <th>344.0284</th>\n",
              "      <th>77.82322</th>\n",
              "      <th>-203.69334</th>\n",
              "      <th>346.57477</th>\n",
              "      <th>91.79831</th>\n",
              "      <th>-50.59186</th>\n",
              "      <th>340.19852</th>\n",
              "      <th>85.209</th>\n",
              "      <th>-166.23322</th>\n",
              "      <th>343.71945</th>\n",
              "      <th>436.56592</th>\n",
              "      <th>16.123152</th>\n",
              "      <th>387.15836</th>\n",
              "      <th>423.04248</th>\n",
              "      <th>-15.423751</th>\n",
              "      <th>352.15213</th>\n",
              "      <th>570.0727</th>\n",
              "      <th>43.69086</th>\n",
              "      <th>475.35153</th>\n",
              "      <th>432.62543</th>\n",
              "      <th>106.81172</th>\n",
              "      <th>363.11978</th>\n",
              "      <th>687.11304</th>\n",
              "      <th>42.357334</th>\n",
              "      <th>433.4393</th>\n",
              "      <th>503.42053</th>\n",
              "      <th>312.2271</th>\n",
              "      <th>366.96002</th>\n",
              "      <th>706.3035</th>\n",
              "      <th>41.69318</th>\n",
              "      <th>419.40616</th>\n",
              "      <th>512.0679</th>\n",
              "      <th>335.33093</th>\n",
              "      <th>368.28622</th>\n",
              "      <th>700.9771</th>\n",
              "      <th>25.304209</th>\n",
              "      <th>433.88956</th>\n",
              "      <th>523.94916</th>\n",
              "      <th>417.58606</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00000071.jpg</td>\n",
              "      <td>tree</td>\n",
              "      <td>388.36478</td>\n",
              "      <td>110.27098</td>\n",
              "      <td>-213.455630</td>\n",
              "      <td>395.37155</td>\n",
              "      <td>96.93155</td>\n",
              "      <td>-185.81432</td>\n",
              "      <td>400.3203</td>\n",
              "      <td>96.48465</td>\n",
              "      <td>-185.809110</td>\n",
              "      <td>405.23358</td>\n",
              "      <td>96.10058</td>\n",
              "      <td>-185.957050</td>\n",
              "      <td>379.55582</td>\n",
              "      <td>97.79178</td>\n",
              "      <td>-190.31395</td>\n",
              "      <td>374.08322</td>\n",
              "      <td>97.81174</td>\n",
              "      <td>-190.21043</td>\n",
              "      <td>368.65628</td>\n",
              "      <td>98.02982</td>\n",
              "      <td>-190.327130</td>\n",
              "      <td>410.81840</td>\n",
              "      <td>101.70912</td>\n",
              "      <td>-22.439323</td>\n",
              "      <td>360.01220</td>\n",
              "      <td>103.76447</td>\n",
              "      <td>-46.524765</td>\n",
              "      <td>396.89227</td>\n",
              "      <td>122.75378</td>\n",
              "      <td>-152.527080</td>\n",
              "      <td>378.38342</td>\n",
              "      <td>123.578575</td>\n",
              "      <td>-158.51303</td>\n",
              "      <td>442.63104</td>\n",
              "      <td>172.80790</td>\n",
              "      <td>46.600853</td>\n",
              "      <td>326.92950</td>\n",
              "      <td>177.87532</td>\n",
              "      <td>...</td>\n",
              "      <td>-316.79495</td>\n",
              "      <td>388.55084</td>\n",
              "      <td>184.129470</td>\n",
              "      <td>-208.84189</td>\n",
              "      <td>395.56600</td>\n",
              "      <td>205.998520</td>\n",
              "      <td>-293.56796</td>\n",
              "      <td>384.96414</td>\n",
              "      <td>188.507610</td>\n",
              "      <td>-191.399830</td>\n",
              "      <td>410.29938</td>\n",
              "      <td>365.34372</td>\n",
              "      <td>-25.141851</td>\n",
              "      <td>342.94855</td>\n",
              "      <td>359.73530</td>\n",
              "      <td>25.054493</td>\n",
              "      <td>389.28012</td>\n",
              "      <td>496.85437</td>\n",
              "      <td>-55.883423</td>\n",
              "      <td>257.87110</td>\n",
              "      <td>439.95187</td>\n",
              "      <td>-183.91222</td>\n",
              "      <td>363.16977</td>\n",
              "      <td>622.08795</td>\n",
              "      <td>143.754850</td>\n",
              "      <td>350.57718</td>\n",
              "      <td>446.33005</td>\n",
              "      <td>206.525270</td>\n",
              "      <td>354.23410</td>\n",
              "      <td>637.75920</td>\n",
              "      <td>159.642230</td>\n",
              "      <td>368.24920</td>\n",
              "      <td>434.00565</td>\n",
              "      <td>244.275050</td>\n",
              "      <td>372.95786</td>\n",
              "      <td>671.47290</td>\n",
              "      <td>21.757889</td>\n",
              "      <td>370.19928</td>\n",
              "      <td>498.01755</td>\n",
              "      <td>226.034360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00000072.jpg</td>\n",
              "      <td>tree</td>\n",
              "      <td>416.07200</td>\n",
              "      <td>182.77090</td>\n",
              "      <td>-35.204967</td>\n",
              "      <td>404.02800</td>\n",
              "      <td>172.27805</td>\n",
              "      <td>-29.43591</td>\n",
              "      <td>401.1836</td>\n",
              "      <td>172.10718</td>\n",
              "      <td>-29.268618</td>\n",
              "      <td>398.48767</td>\n",
              "      <td>171.91978</td>\n",
              "      <td>-29.301407</td>\n",
              "      <td>407.31656</td>\n",
              "      <td>173.09401</td>\n",
              "      <td>-70.20080</td>\n",
              "      <td>406.11887</td>\n",
              "      <td>173.29039</td>\n",
              "      <td>-70.21993</td>\n",
              "      <td>405.02112</td>\n",
              "      <td>173.70406</td>\n",
              "      <td>-70.406525</td>\n",
              "      <td>382.14563</td>\n",
              "      <td>180.17886</td>\n",
              "      <td>20.811386</td>\n",
              "      <td>393.64810</td>\n",
              "      <td>183.88905</td>\n",
              "      <td>-162.111220</td>\n",
              "      <td>409.52655</td>\n",
              "      <td>195.06487</td>\n",
              "      <td>-12.207339</td>\n",
              "      <td>411.40585</td>\n",
              "      <td>195.515350</td>\n",
              "      <td>-63.95105</td>\n",
              "      <td>374.17610</td>\n",
              "      <td>225.01213</td>\n",
              "      <td>88.169950</td>\n",
              "      <td>375.27496</td>\n",
              "      <td>223.63948</td>\n",
              "      <td>...</td>\n",
              "      <td>-82.91035</td>\n",
              "      <td>348.88492</td>\n",
              "      <td>35.230410</td>\n",
              "      <td>-530.29944</td>\n",
              "      <td>355.45310</td>\n",
              "      <td>37.445335</td>\n",
              "      <td>-44.26539</td>\n",
              "      <td>349.30002</td>\n",
              "      <td>40.501446</td>\n",
              "      <td>-490.643040</td>\n",
              "      <td>387.40634</td>\n",
              "      <td>414.36212</td>\n",
              "      <td>119.257990</td>\n",
              "      <td>384.09506</td>\n",
              "      <td>417.40286</td>\n",
              "      <td>-119.230300</td>\n",
              "      <td>379.75217</td>\n",
              "      <td>546.24220</td>\n",
              "      <td>159.789140</td>\n",
              "      <td>374.57166</td>\n",
              "      <td>549.12720</td>\n",
              "      <td>-80.69852</td>\n",
              "      <td>357.68304</td>\n",
              "      <td>657.48773</td>\n",
              "      <td>230.061650</td>\n",
              "      <td>362.53793</td>\n",
              "      <td>671.60830</td>\n",
              "      <td>-9.155198</td>\n",
              "      <td>344.97174</td>\n",
              "      <td>673.03180</td>\n",
              "      <td>231.262190</td>\n",
              "      <td>347.65620</td>\n",
              "      <td>689.19977</td>\n",
              "      <td>-10.802441</td>\n",
              "      <td>387.69696</td>\n",
              "      <td>699.58844</td>\n",
              "      <td>150.661130</td>\n",
              "      <td>400.38828</td>\n",
              "      <td>717.13680</td>\n",
              "      <td>-120.740700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00000073.jpg</td>\n",
              "      <td>tree</td>\n",
              "      <td>379.91080</td>\n",
              "      <td>266.09515</td>\n",
              "      <td>-194.611860</td>\n",
              "      <td>383.64435</td>\n",
              "      <td>260.21982</td>\n",
              "      <td>-180.70596</td>\n",
              "      <td>386.0421</td>\n",
              "      <td>259.97330</td>\n",
              "      <td>-180.716770</td>\n",
              "      <td>388.56720</td>\n",
              "      <td>259.74557</td>\n",
              "      <td>-180.797150</td>\n",
              "      <td>376.00890</td>\n",
              "      <td>261.27264</td>\n",
              "      <td>-175.90521</td>\n",
              "      <td>373.58930</td>\n",
              "      <td>261.57263</td>\n",
              "      <td>-175.74963</td>\n",
              "      <td>371.23196</td>\n",
              "      <td>262.05260</td>\n",
              "      <td>-175.801400</td>\n",
              "      <td>392.73172</td>\n",
              "      <td>263.79047</td>\n",
              "      <td>-99.468820</td>\n",
              "      <td>369.32077</td>\n",
              "      <td>266.20540</td>\n",
              "      <td>-81.819810</td>\n",
              "      <td>385.04770</td>\n",
              "      <td>272.75098</td>\n",
              "      <td>-164.952400</td>\n",
              "      <td>376.51108</td>\n",
              "      <td>273.797760</td>\n",
              "      <td>-159.41386</td>\n",
              "      <td>408.11716</td>\n",
              "      <td>295.55927</td>\n",
              "      <td>-113.909676</td>\n",
              "      <td>360.40920</td>\n",
              "      <td>295.80190</td>\n",
              "      <td>...</td>\n",
              "      <td>-243.89938</td>\n",
              "      <td>383.48680</td>\n",
              "      <td>171.857450</td>\n",
              "      <td>-146.58755</td>\n",
              "      <td>383.71518</td>\n",
              "      <td>168.139470</td>\n",
              "      <td>-217.12502</td>\n",
              "      <td>381.67313</td>\n",
              "      <td>174.390950</td>\n",
              "      <td>-122.309700</td>\n",
              "      <td>387.50702</td>\n",
              "      <td>413.32840</td>\n",
              "      <td>-21.220890</td>\n",
              "      <td>354.29500</td>\n",
              "      <td>404.51324</td>\n",
              "      <td>21.353102</td>\n",
              "      <td>375.36926</td>\n",
              "      <td>494.82898</td>\n",
              "      <td>-59.317833</td>\n",
              "      <td>297.32147</td>\n",
              "      <td>439.80550</td>\n",
              "      <td>-184.42528</td>\n",
              "      <td>363.38450</td>\n",
              "      <td>570.73290</td>\n",
              "      <td>78.814560</td>\n",
              "      <td>356.43405</td>\n",
              "      <td>458.98310</td>\n",
              "      <td>90.715500</td>\n",
              "      <td>360.48450</td>\n",
              "      <td>579.22235</td>\n",
              "      <td>89.375435</td>\n",
              "      <td>370.17220</td>\n",
              "      <td>453.60016</td>\n",
              "      <td>119.901700</td>\n",
              "      <td>366.07294</td>\n",
              "      <td>603.98350</td>\n",
              "      <td>-17.750605</td>\n",
              "      <td>355.62885</td>\n",
              "      <td>485.28730</td>\n",
              "      <td>83.178470</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00000074.jpg</td>\n",
              "      <td>tree</td>\n",
              "      <td>387.38617</td>\n",
              "      <td>194.40001</td>\n",
              "      <td>-146.087720</td>\n",
              "      <td>395.34540</td>\n",
              "      <td>183.81131</td>\n",
              "      <td>-129.62207</td>\n",
              "      <td>399.9459</td>\n",
              "      <td>183.33746</td>\n",
              "      <td>-129.567250</td>\n",
              "      <td>404.75406</td>\n",
              "      <td>182.90987</td>\n",
              "      <td>-129.657780</td>\n",
              "      <td>382.90796</td>\n",
              "      <td>186.17029</td>\n",
              "      <td>-117.79378</td>\n",
              "      <td>379.04324</td>\n",
              "      <td>186.90290</td>\n",
              "      <td>-117.66787</td>\n",
              "      <td>375.26978</td>\n",
              "      <td>187.90160</td>\n",
              "      <td>-117.742640</td>\n",
              "      <td>415.51056</td>\n",
              "      <td>192.75706</td>\n",
              "      <td>-45.118893</td>\n",
              "      <td>375.61685</td>\n",
              "      <td>197.79523</td>\n",
              "      <td>4.479250</td>\n",
              "      <td>398.61914</td>\n",
              "      <td>207.68526</td>\n",
              "      <td>-115.739370</td>\n",
              "      <td>382.99606</td>\n",
              "      <td>209.842820</td>\n",
              "      <td>-101.34446</td>\n",
              "      <td>442.69600</td>\n",
              "      <td>250.26843</td>\n",
              "      <td>-88.944954</td>\n",
              "      <td>364.00800</td>\n",
              "      <td>256.20868</td>\n",
              "      <td>...</td>\n",
              "      <td>-167.74503</td>\n",
              "      <td>390.05304</td>\n",
              "      <td>53.841034</td>\n",
              "      <td>-57.28695</td>\n",
              "      <td>387.37888</td>\n",
              "      <td>59.927210</td>\n",
              "      <td>-145.65118</td>\n",
              "      <td>387.86510</td>\n",
              "      <td>60.296326</td>\n",
              "      <td>-35.648117</td>\n",
              "      <td>411.01956</td>\n",
              "      <td>446.61105</td>\n",
              "      <td>-38.402245</td>\n",
              "      <td>351.26395</td>\n",
              "      <td>436.02173</td>\n",
              "      <td>38.458930</td>\n",
              "      <td>389.53293</td>\n",
              "      <td>582.03170</td>\n",
              "      <td>-54.347630</td>\n",
              "      <td>263.08790</td>\n",
              "      <td>521.03186</td>\n",
              "      <td>-25.35692</td>\n",
              "      <td>389.30154</td>\n",
              "      <td>694.62910</td>\n",
              "      <td>77.697890</td>\n",
              "      <td>367.00350</td>\n",
              "      <td>501.36597</td>\n",
              "      <td>303.952420</td>\n",
              "      <td>393.56195</td>\n",
              "      <td>708.81720</td>\n",
              "      <td>88.372830</td>\n",
              "      <td>393.06020</td>\n",
              "      <td>485.57800</td>\n",
              "      <td>338.241500</td>\n",
              "      <td>374.15720</td>\n",
              "      <td>734.30280</td>\n",
              "      <td>-40.495872</td>\n",
              "      <td>364.88290</td>\n",
              "      <td>530.61740</td>\n",
              "      <td>350.138800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00000075.jpg</td>\n",
              "      <td>tree</td>\n",
              "      <td>395.14548</td>\n",
              "      <td>273.39102</td>\n",
              "      <td>-164.089450</td>\n",
              "      <td>399.60925</td>\n",
              "      <td>266.32870</td>\n",
              "      <td>-146.78110</td>\n",
              "      <td>403.2792</td>\n",
              "      <td>266.01544</td>\n",
              "      <td>-146.747560</td>\n",
              "      <td>407.06854</td>\n",
              "      <td>265.69913</td>\n",
              "      <td>-146.880900</td>\n",
              "      <td>388.54767</td>\n",
              "      <td>268.13920</td>\n",
              "      <td>-140.89032</td>\n",
              "      <td>384.81396</td>\n",
              "      <td>268.82852</td>\n",
              "      <td>-140.69461</td>\n",
              "      <td>381.14075</td>\n",
              "      <td>269.69962</td>\n",
              "      <td>-140.737690</td>\n",
              "      <td>412.94530</td>\n",
              "      <td>273.48782</td>\n",
              "      <td>-57.789577</td>\n",
              "      <td>377.19130</td>\n",
              "      <td>278.14172</td>\n",
              "      <td>-32.742786</td>\n",
              "      <td>403.19160</td>\n",
              "      <td>283.28000</td>\n",
              "      <td>-132.050420</td>\n",
              "      <td>389.48383</td>\n",
              "      <td>285.135400</td>\n",
              "      <td>-124.48342</td>\n",
              "      <td>429.17538</td>\n",
              "      <td>314.30140</td>\n",
              "      <td>-89.010260</td>\n",
              "      <td>371.44635</td>\n",
              "      <td>314.01953</td>\n",
              "      <td>...</td>\n",
              "      <td>-198.82219</td>\n",
              "      <td>394.81030</td>\n",
              "      <td>170.076660</td>\n",
              "      <td>-111.02762</td>\n",
              "      <td>393.25244</td>\n",
              "      <td>174.197940</td>\n",
              "      <td>-180.46257</td>\n",
              "      <td>391.65518</td>\n",
              "      <td>176.158190</td>\n",
              "      <td>-94.509180</td>\n",
              "      <td>412.74625</td>\n",
              "      <td>458.43158</td>\n",
              "      <td>-40.850050</td>\n",
              "      <td>370.82184</td>\n",
              "      <td>448.37997</td>\n",
              "      <td>40.936363</td>\n",
              "      <td>394.89010</td>\n",
              "      <td>559.04930</td>\n",
              "      <td>-96.868060</td>\n",
              "      <td>297.81564</td>\n",
              "      <td>481.71643</td>\n",
              "      <td>-239.55182</td>\n",
              "      <td>390.61377</td>\n",
              "      <td>651.09674</td>\n",
              "      <td>19.639647</td>\n",
              "      <td>372.58517</td>\n",
              "      <td>526.62160</td>\n",
              "      <td>8.883306</td>\n",
              "      <td>392.14578</td>\n",
              "      <td>659.75970</td>\n",
              "      <td>27.476542</td>\n",
              "      <td>392.75766</td>\n",
              "      <td>524.19400</td>\n",
              "      <td>35.229378</td>\n",
              "      <td>379.71613</td>\n",
              "      <td>691.85640</td>\n",
              "      <td>-86.411280</td>\n",
              "      <td>362.15158</td>\n",
              "      <td>561.83636</td>\n",
              "      <td>-11.668729</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 101 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e0423dac-9211-41cf-a736-1de352035cb1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e0423dac-9211-41cf-a736-1de352035cb1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e0423dac-9211-41cf-a736-1de352035cb1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   00000070.jpg  tree   347.6777  ...  433.88956  523.94916   417.58606\n",
              "0  00000071.jpg  tree  388.36478  ...  370.19928  498.01755  226.034360\n",
              "1  00000072.jpg  tree  416.07200  ...  400.38828  717.13680 -120.740700\n",
              "2  00000073.jpg  tree  379.91080  ...  355.62885  485.28730   83.178470\n",
              "3  00000074.jpg  tree  387.38617  ...  364.88290  530.61740  350.138800\n",
              "4  00000075.jpg  tree  395.14548  ...  362.15158  561.83636  -11.668729\n",
              "\n",
              "[5 rows x 101 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfE7C9wHel_7"
      },
      "source": [
        "# Step 2: Classification\n",
        "\n",
        "**Important!!** Check that you are using the same classification parameters as while building classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4eaOJpoEvFl",
        "outputId": "71891b6b-bd5b-41df-ad9d-a2e4da0bdf70",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 214
        }
      },
      "source": [
        "# Upload your video.\n",
        "uploaded = files.upload()\n",
        "os.listdir('.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-966bd2a0-2564-4774-aa33-97f336d7caf6\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-966bd2a0-2564-4774-aa33-97f336d7caf6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving How to Do Downward Facing Dog - Yoga Pose Tutorial (Part 1 Vinyasa Essentials Tutorial Series).mp4 to How to Do Downward Facing Dog - Yoga Pose Tutorial (Part 1 Vinyasa Essentials Tutorial Series).mp4\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config',\n",
              " 'How to Do Downward Facing Dog - Yoga Pose Tutorial (Part 1 Vinyasa Essentials Tutorial Series).mp4',\n",
              " 'yoga_poses_csvs_out',\n",
              " 'drive',\n",
              " 'yoga_poses_csvs_out.csv',\n",
              " 'sample_data']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYkZJ3a_2MW_"
      },
      "source": [
        "# Specify your video name and target pose class to count the repetitions.\n",
        "video_path = '/content/How to Do Downward Facing Dog - Yoga Pose Tutorial (Part 1 Vinyasa Essentials Tutorial Series).mp4'\n",
        "class_name='downdog'\n",
        "out_video_path = 'goddess-sample-out.mp4'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3gGMDE0R2pe"
      },
      "source": [
        "# Open the video.\n",
        "import cv2\n",
        "\n",
        "video_cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Get some video parameters to generate output video with classificaiton.\n",
        "video_n_frames = video_cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "video_fps = video_cap.get(cv2.CAP_PROP_FPS)\n",
        "video_width = int(video_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "video_height = int(video_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pose_embedder"
      ],
      "metadata": {
        "id": "9TidzU9XNuhW",
        "outputId": "55541d7b-7fff-48ec-bbb1-d783a871dbf9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.FullBodyPoseEmbedder at 0x7f603b13df50>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ceck that you are using the same parameters as during bootstrapping.\n",
        "pose_classifier = PoseClassifier(\n",
        "    pose_samples_folder=pose_samples_folder,\n",
        "    pose_embedder=pose_embedder,\n",
        "    top_n_by_max_distance=30,\n",
        "    top_n_by_mean_distance=10)"
      ],
      "metadata": {
        "id": "wijpK9-gODTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7t_ACEmTSOhr"
      },
      "source": [
        "# Initilize tracker, classifier and counter.\n",
        "# Do that before every video as all of them have state.\n",
        "from mediapipe.python.solutions import pose as mp_pose\n",
        "\n",
        "\n",
        "# Folder with pose class CSVs. That should be the same folder you using while\n",
        "# building classifier to output CSVs.\n",
        "pose_samples_folder = 'yoga_poses_csvs_out'\n",
        "\n",
        "# Initialize tracker.\n",
        "pose_tracker = mp_pose.Pose(upper_body_only=False)\n",
        "\n",
        "# Initialize embedder.\n",
        "#pose_embedder = FullBodyPoseEmbedder()\n",
        "\n",
        "# Initialize classifier.\n",
        "\n",
        "\n",
        "# # Uncomment to validate target poses used by classifier and find outliers.\n",
        "# outliers = pose_classifier.find_pose_sample_outliers()\n",
        "# print('Number of pose sample outliers (consider removing them): ', len(outliers))\n",
        "\n",
        "# Initialize EMA smoothing.\n",
        "pose_classification_filter = EMADictSmoothing(\n",
        "    window_size=10,\n",
        "    alpha=0.2)\n",
        "\n",
        "# Initialize counter.\n",
        "repetition_counter = RepetitionCounter(\n",
        "    class_name=class_name,\n",
        "    enter_threshold=6,\n",
        "    exit_threshold=4)\n",
        "\n",
        "# Initialize renderer.\n",
        "pose_classification_visualizer = PoseClassificationVisualizer(\n",
        "    class_name=class_name,\n",
        "    plot_x_max=video_n_frames,\n",
        "    # Graphic looks nicer if it's the same as `top_n_by_mean_distance`.\n",
        "    plot_y_max=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run classification on a video.\n",
        "import os\n",
        "import tqdm\n",
        "\n",
        "from mediapipe.python.solutions import drawing_utils as mp_drawing\n",
        "\n",
        "\n",
        "# Open output video.\n",
        "out_video = cv2.VideoWriter(out_video_path, cv2.VideoWriter_fourcc(*'mp4v'), video_fps, (video_width, video_height))\n",
        "\n",
        "frame_idx = 0\n",
        "output_frame = None\n",
        "with tqdm.tqdm(total=video_n_frames, position=0, leave=True) as pbar:\n",
        "  while True:\n",
        "    # Get next frame of the video.\n",
        "    success, input_frame = video_cap.read()\n",
        "    if not success:\n",
        "      break\n",
        "\n",
        "    # Run pose tracker.\n",
        "    input_frame = cv2.cvtColor(input_frame, cv2.COLOR_BGR2RGB)\n",
        "    result = pose_tracker.process(image=input_frame)\n",
        "    pose_landmarks = result.pose_landmarks\n",
        "\n",
        "    # Draw pose prediction.\n",
        "    output_frame = input_frame.copy()\n",
        "    if pose_landmarks is not None:\n",
        "      mp_drawing.draw_landmarks(\n",
        "          image=output_frame,\n",
        "          landmark_list=pose_landmarks,\n",
        "          connections=mp_pose.POSE_CONNECTIONS)\n",
        "    \n",
        "    if pose_landmarks is not None:\n",
        "      # Get landmarks.\n",
        "      frame_height, frame_width = output_frame.shape[0], output_frame.shape[1]\n",
        "      pose_landmarks = np.array([[lmk.x * frame_width, lmk.y * frame_height, lmk.z * frame_width]\n",
        "                                 for lmk in pose_landmarks.landmark], dtype=np.float32)\n",
        "      assert pose_landmarks.shape == (33, 3), 'Unexpected landmarks shape: {}'.format(pose_landmarks.shape)\n",
        "\n",
        "      # Classify the pose on the current frame.\n",
        "      pose_classification = pose_classifier(pose_landmarks)\n",
        "\n",
        "      # Smooth classification using EMA.\n",
        "      pose_classification_filtered = pose_classification_filter(pose_classification)\n",
        "\n",
        "      # Count repetitions.\n",
        "      repetitions_count = repetition_counter(pose_classification_filtered)\n",
        "    else:\n",
        "      # No pose => no classification on current frame.\n",
        "      pose_classification = None\n",
        "\n",
        "      # Still add empty classification to the filter to maintaing correct\n",
        "      # smoothing for future frames.\n",
        "      pose_classification_filtered = pose_classification_filter(dict())\n",
        "      pose_classification_filtered = None\n",
        "\n",
        "      # Don't update the counter presuming that person is 'frozen'. Just\n",
        "      # take the latest repetitions count.\n",
        "      repetitions_count = repetition_counter.n_repeats\n",
        "\n",
        "    # Draw classification plot and repetition counter.\n",
        "    output_frame = pose_classification_visualizer(\n",
        "        frame=output_frame,\n",
        "        pose_classification=pose_classification,\n",
        "        pose_classification_filtered=pose_classification_filtered,\n",
        "        repetitions_count=repetitions_count)\n",
        "\n",
        "    # Save the output frame.\n",
        "    out_video.write(cv2.cvtColor(np.array(output_frame), cv2.COLOR_RGB2BGR))\n",
        "\n",
        "    # Show intermediate frames of the video to track progress.\n",
        "    if frame_idx % 50 == 0:\n",
        "      show_image(output_frame)\n",
        "\n",
        "    frame_idx += 1\n",
        "    pbar.update()\n",
        "\n",
        "# Close output video.\n",
        "out_video.release()\n",
        "\n",
        "# Release MediaPipe resources.\n",
        "pose_tracker.close()\n",
        "\n",
        "# Show the last frame of the video.\n",
        "if output_frame is not None:\n",
        "  show_image(output_frame)"
      ],
      "metadata": {
        "id": "hep-GGldA2fK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJFftPiQE56E",
        "outputId": "05f5e500-66c4-4abf-8eee-dae7ba1135fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "# Download generated video\n",
        "files.download(out_video_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_618f31c3-ffb6-42a8-926b-b53ae7bc0406\", \"goddess-sample-out.mp4\", 44)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}